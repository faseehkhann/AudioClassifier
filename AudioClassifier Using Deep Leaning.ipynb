{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62ab748",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af6e42",
   "metadata": {},
   "source": [
    "## 1.1 Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-io matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18384f3f",
   "metadata": {},
   "source": [
    "## 1.2 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf \n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5871f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPUCHIN_FILE = os.path.join('data', 'Parsed_Capuchinbird_Clips', 'XC3776-3.wav')\n",
    "NOT_CAPUCHIN_FILE = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips', 'afternoon-birds-song-in-forest-0.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f29b44",
   "metadata": {},
   "source": [
    "# 2. Building Dataloading Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3eb98",
   "metadata": {},
   "source": [
    "The Following Function gets the path of your audio file. Decode it into to wave and than resample it into 1k Hz mono signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d1a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_1k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 1000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=1000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = load_wav_1k_mono(CAPUCHIN_FILE)\n",
    "nwave = load_wav_1k_mono(NOT_CAPUCHIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wave)\n",
    "plt.plot(nwave)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a353cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = os.path.join('data', 'Parsed_Capuchinbird_Clips')\n",
    "NEG = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a1742",
   "metadata": {},
   "source": [
    "# 3. Manipulating Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = tf.data.Dataset.list_files(POS+'\\*.wav')\n",
    "neg = tf.data.Dataset.list_files(NEG+'\\*.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30399178",
   "metadata": {},
   "source": [
    "## 3.1 Labling Tensorflow Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
    "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04851854",
   "metadata": {},
   "source": [
    "## 3.2 Calculating Wave Cycle Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640face4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')):\n",
    "    tensor_wave = load_wav_1k_mono(os.path.join('data', 'Parsed_Capuchinbird_Clips', file))\n",
    "    lengths.append(len(tensor_wave))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2891d6",
   "metadata": {},
   "source": [
    "## 3.3 Calculating Mean, Median and Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea214c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f021b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_max(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6a1da",
   "metadata": {},
   "source": [
    "# 4. Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9256f5",
   "metadata": {},
   "source": [
    "## 4.1 Building Preprocessing Dataset to get Spectrogram from Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b36a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    wav = load_wav_1k_mono(file_path)\n",
    "    wav = wav[:3500]\n",
    "    zero_padding = tf.zeros([3500] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c380ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram, label = preprocess(filepath, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(tf.transpose(spectrogram)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3adff",
   "metadata": {},
   "source": [
    "# 5. Training and Testing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f418feb",
   "metadata": {},
   "source": [
    "## 5.1 Creating Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa631224",
   "metadata": {},
   "source": [
    "## 5.2 Distributing Dataset into Training and Teating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(36)\n",
    "test = data.skip(36).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(tf.transpose(samples[0])[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069712b",
   "metadata": {},
   "source": [
    "# 6. Building Deep Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbb030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(100, 257,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0cdc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=4, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839f4563",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(hist.history['accuracy'], 'r')\n",
    "plt.plot(hist.history['val_accuracy'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff513f29",
   "metadata": {},
   "source": [
    "# 7. Make a Prediction on a Single Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e9ed5",
   "metadata": {},
   "source": [
    "## 7.1 Making a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60623bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b14037",
   "metadata": {},
   "source": [
    "## 7.2 Extracting Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5d960",
   "metadata": {},
   "source": [
    "# 8. Preprocessing Unseen MP3 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa24f2",
   "metadata": {},
   "source": [
    "## 8.1 Build Function that can reshape MP3 Data and convert it into Wave Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mp3_1k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    res = tfio.audio.AudioIOTensor(filename)\n",
    "    # Convert to tensor and combine channels \n",
    "    tensor = res.to_tensor()\n",
    "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2 \n",
    "    # Extract sample rate and cast\n",
    "    sample_rate = res.rate\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Resample to 16 kHz\n",
    "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa78602",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = load_mp3_1k_mono(mp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c5a65",
   "metadata": {},
   "source": [
    "## 8.2. Build Function to Convert Wave to Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mp3(sample, index):\n",
    "    sample = sample[0]\n",
    "    zero_padding = tf.zeros([3500] - tf.shape(sample), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, sample],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9806ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectogram = preprocess_mp3(samples, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(tf.transpose(spectrogram)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea03ba",
   "metadata": {},
   "source": [
    "## 9.3 Convert Longer Clips into Small Clips and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4885e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=3500, sequence_stride=48000, batch_size=1)\n",
    "audio_slices = audio_slices.map(preprocess_mp3)\n",
    "audio_slices = audio_slices.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbcffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(audio_slices)\n",
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513bc960",
   "metadata": {},
   "source": [
    "# 10. Making Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02aecd",
   "metadata": {},
   "source": [
    "## 10.1 Loop over all recordings and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for file in os.listdir(os.path.join('data', 'Forest Recordings')):\n",
    "    FILEPATH = os.path.join('data','Forest Recordings', file)\n",
    "    \n",
    "    wav = load_mp3_1k_mono(FILEPATH)\n",
    "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=3500, sequence_stride=48000, batch_size=1)\n",
    "    audio_slices = audio_slices.map(preprocess_mp3)\n",
    "    audio_slices = audio_slices.batch(64)\n",
    "    \n",
    "    yhat = model.predict(audio_slices)\n",
    "    \n",
    "    results[file] = yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21b584",
   "metadata": {},
   "source": [
    "## 10.2 Convert Predictions into Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = {}\n",
    "for file, logits in results.items():\n",
    "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5417eea",
   "metadata": {},
   "source": [
    "## 10.3 Group Consecutive Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4888f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "postprocessed = {}\n",
    "for file, scores in class_preds.items():\n",
    "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
    "postprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f01511",
   "metadata": {},
   "source": [
    "# 11. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a941b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(['recording', 'capuchin_calls'])\n",
    "    for key, value in postprocessed.items():\n",
    "        writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
